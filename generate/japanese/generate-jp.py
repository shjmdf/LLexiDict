import os
import json
import asyncio
import re
import sqlite3
import time
from openai import AsyncOpenAI

# ================= é…ç½® =================
API_KEY = ""
BASE_URL = ""
MODEL_NAME = ""
CONCURRENCY = 128

SOURCE_FILE = "jp-clean.txt"
DB_NAME = "japanese_dictionary.db"
SYSTEM_MESSAGE_CONTENT = (
    "You are a Japanese dictionary generator. Your response MUST be ONLY the requested JSON object. "
    "DO NOT include any explanatory text, preambles, comments, or chain-of-thought before or after the JSON block. "
    "Start immediately with '{' and end with '}'."
)
# ================= æ¶ˆè´¹è€… (å†™å…¥çº¿ç¨‹) =================
async def db_writer(queue):
    print("æ•°æ®åº“å†™å…¥çº¿ç¨‹å¯åŠ¨...")
    conn = sqlite3.connect(DB_NAME)
    cursor = conn.cursor()
    cursor.execute('PRAGMA journal_mode=WAL;')
    
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS dictionary (
            word TEXT PRIMARY KEY,
            keywords TEXT,
            data JSON,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )
    ''')
    conn.commit()

    batch_buffer = []
    last_commit = time.time()

    while True:
        item = await queue.get()
        if item is None: break
        
        word, keywords, data_str = item
        batch_buffer.append((word, keywords, data_str))

        if len(batch_buffer) >= 50 or (time.time() - last_commit > 3 and batch_buffer):
            try:
                cursor.executemany("INSERT OR REPLACE INTO dictionary (word, keywords, data) VALUES (?, ?, ?)", batch_buffer)
                conn.commit()
                batch_buffer = []
                last_commit = time.time()
            except Exception as e:
                print(f"DB Error: {e}")

        queue.task_done()

    if batch_buffer:
        cursor.executemany("INSERT OR REPLACE INTO dictionary (word, keywords, data) VALUES (?, ?, ?)", batch_buffer)
        conn.commit()
    
    conn.close()
    print("æ•°æ®åº“å†™å…¥å®Œæˆã€‚")

# ================= æ—¥è¯­ Prompt =================
def get_japanese_prompt(word):
    return f"""
    Role: Meticulous and Verifying Japanese-Chinese Lexicographer.
    Target Word: "{word}" (Japanese).
    Target Audience: Advanced Learners (N1/N2) aiming for native-like nuance.

    **Core Principles: ACCURACY > COMPLETENESS. VERIFICATION is MANDATORY.**

    **ğŸ”¥ğŸ”¥ CRITICAL VERIFICATION STEPS (Must perform before generating): ğŸ”¥ğŸ”¥**

    1.  **AMBIGUITY CHECK:**
        * Does "{word}" have multiple, distinct meanings or parts of speech? (e.g., `ãã†ã„ã†` as a pre-noun adjective vs. `ãã†è¨€ã†` as a verb phrase).
        * **Action:** You MUST select the **single most common/primary meaning** associated with the `word` spelling.
        * **Constraint:** All subsequent fields (`pos`, `grammar_meta`, `inflections_detail`, `senses`, `examples`) MUST align 100% with this SINGLE chosen meaning. **Do not mix meanings.**

    2.  **DATA CONSISTENCY CHECK:**
        * `pitch_accent` ([num]) MUST exactly match the `pitch_visual` (L/H graph).
        * `inflections_detail` (æ´»ç”¨å½¢) MUST logically match the `pos` (è¯æ€§) and `grammar_meta` (è¯­æ³•). (e.g., If `pos` is 'n.', `inflections_detail.forms` MUST be an empty array `[]`).
        * All `examples` MUST use the word in the exact `pos` and `sense` defined above.

    3.  **PRECISION CHECK:**
        * `ruby` (æŒ¯å‡å): Must be 100% accurate, mapping the `kana` reading precisely to the `jp` kanji. **Pay extreme attention to ãŠãã‚ŠãŒãª (okurigana)** (e.g., `ãŠæ›ã‘ã—ã¦` -> `ãŠæ›(ã‹)ã‘ã—ã¦`).
        * `pitch_accent`: Source from standard lexicographical data (e.g., NHK). **If the pitch accent is unknown or widely disputed, use `"[?] Unknown"` instead of guessing.**

    ---
    Output STRICT JSON (No Markdown):
    {{
      "word": "Standard Written Form (e.g. é£Ÿã¹ã‚‹, ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿, è–”è–‡)",
      
      "readings": {{
          "kana": "Full Hiragana (e.g. ãŸã¹ã‚‹, ã“ã‚“ã´ã‚…ãƒ¼ãŸ)",
          "katakana": "Full Katakana (e.g. ã‚¿ãƒ™ãƒ«, ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿) - CRITICAL for search",
          "romaji": "Hepburn",
          "pitch_accent": "[num] Type (e.g. [2] Nakadaka) or [?] Unknown",
          "pitch_visual": "Text graph (e.g. LHHLL) or 'N/A'"
      }},

      "pos": "v. (Godan/Ichidan) / adj-i / adj-na / n. / exp. / rentaishi", // **Added 'rentaishi'**
      
      "grammar_meta": {{
          "verb_group": "Godan / Ichidan / Suru / N/A",
          "transitivity": "Transitive (ä»–) / Intransitive (è‡ª) / N/A",
          "paired_verb": "Counterpart (e.g. 'kieru' -> 'kesu') or null"
      }},

      "inflections_detail": {{
          "forms": [
             // "Te-form", "Nai-form", "Ta-form", etc.
             // **If 'pos' is not a verb/adjective, this MUST be []**
          ]
      }},

      "search_keywords": [
          "Must include: Kanji form",
          "Must include: Kana reading (Hiragana)",
          "Must include: Katakana reading (e.g. ã‚¿ãƒ™ãƒ«)", 
          "Must include: Romaji",
          "Must include: All generated conjugated forms (if any)"
      ],

      "script_nuance": "Analysis: Is Kanji standard? Is it often written in Katakana for emphasis, slang, or biological naming? (e.g. 'Often written as ãƒã‚³ in scientific contexts')",
      
      "cultural_decoding": {{
          "register": "Teineigo / Kudaketa / Sonkeigo / Kenjougo / Neutral",
          "air_reading": "Hidden nuance / Implication",
          "caution": "Taboo / Usage warning / Common Pitfall (e.g. 'Do not confuse with X')"
      }},

      "senses": [
        {{
          "definitions": {{//be specific and concise, accurate and contextual
              "cn": "Natural Simplified Chinese, with cultural context and explicit usage",
              "jp": "Kokugo Jiten definition, with cultural context and explicit usage",
              "en": "Logical English definition, precise and contextual"
          }},
          "core_image": "Mental picture / Underlying concept",
          "collocations": [
              "Particle Usage (~ni vs ~wo)",
              "Set Phrase / Yojijukugo"
          ],
          "synonym_discrimination": "Compare with similar Kanji/Words",
          "examples": [
            {{
               "jp": "Natural sentence with Kanji",
               "kana": "Full Hiragana reading",
               "ruby": "Kanji(Kana) format (MUST BE 100% ACCURATE)",
               "cn": "Translation"
            }}
          ]
        }}
      ]
    }}
    Final Output Constraint: Your entire response must consist of the complete, valid JSON object, starting with '{{' and ending with '}}'. Nothing else.
    """

# ================= API Worker =================
async def worker(sem, client, queue, word):
    async with sem:
        for attempt in range(3):
            try:
                response = await asyncio.wait_for(
                    client.chat.completions.create(
                        model=MODEL_NAME,
                        messages=[{"role": "system", "content": "You are a Japanese dictionary generator. Your response MUST be ONLY the requested JSON object. DO NOT include any explanatory text, preambles, comments, or chain-of-thought before or after the JSON block. Start immediately with '{' and end with '}'."}, 
                        {"role": "user", "content": get_japanese_prompt(word)}],
                        response_format={"type": "json_object"},
                        temperature=0.1
                    ),
                    timeout=120
                )
                
                raw_content = response.choices[0].message.content
                
                match = re.search(r'\{.*\}', raw_content.strip(), re.DOTALL)
                
                if not match:
                    raise ValueError("JSON_BLOCK_NOT_FOUND: æ— æ³•åœ¨åŸå§‹è¾“å‡ºä¸­éš”ç¦»å®Œæ•´çš„ {} ç»“æ„ã€‚")

                content_json_only = match.group(0)
                
                # æ­£åˆ™è¡¨è¾¾å¼æ›¿æ¢å°¾éƒ¨å¤šä½™ç¬¦å·
                content_json_clean = re.sub(r',\s*([\]\}])', r'\1', content_json_only)

                data = json.loads(content_json_clean)
                
                keywords_list = data.get("search_keywords", [])
                if word not in keywords_list:
                    keywords_list.append(word)
                keywords_str = " ".join([str(x) for x in keywords_list]).lower()
                
                await queue.put((word, keywords_str, content_json_clean))
                print(f"âœ… {word}")
                return
                
            except json.JSONDecodeError as e:
                # JSON å†…éƒ¨æœ‰æ›´å¤æ‚çš„é”™è¯¯ï¼ˆå¦‚ç¼ºå°‘å¼•å·æˆ–å†’å·ï¼‰
                print(f"âŒ JSON PARSE FAIL (Internal): {word} | Error: {e.msg}")
                await asyncio.sleep(1) 
                continue
            except ValueError as e:
                print(f"âŒ JSON BLOCK FAIL: {word} | Error: {e}")  
                await asyncio.sleep(1)
                continue
            except Exception as e:
                error_str = str(e)
                if "429" in error_str:
                    print(f"â³ é™æµ: {word}")
                    await asyncio.sleep(5)
                    continue
                else:
                    print(f"âŒ {word}: {e}")
                    await asyncio.sleep(1)
                    continue
        print(f"ğŸ’€ {word} å¤±è´¥")

# ================= ä¸»ç¨‹åº =================
async def main():
    # æ£€æŸ¥è¿›åº¦
    conn = sqlite3.connect(DB_NAME)
    try:
        existing = set(row[0] for row in conn.execute("SELECT word FROM dictionary"))
    except:
        existing = set()
    conn.close()
    print(f"ğŸ“‚ åº“ä¸­å·²æœ‰ {len(existing)} ä¸ªè¯ã€‚")

    # è¯»å–åˆ—è¡¨
    base_dir = os.path.dirname(os.path.abspath(__file__))
    file_path = os.path.join(base_dir, SOURCE_FILE)
    if not os.path.exists(file_path):
        print(f"âŒ æ‰¾ä¸åˆ° {SOURCE_FILE}")
        return

    with open(file_path, 'r', encoding='utf-8') as f:
        all_words = [line.strip() for line in f if line.strip()]

    # è¿‡æ»¤ä»»åŠ¡
    tasks_to_run = [w for w in all_words if w not in existing]
    print(f"ğŸ å‰©ä½™ä»»åŠ¡: {len(tasks_to_run)} ä¸ªã€‚ä½¿ç”¨æ¨¡å‹: {MODEL_NAME}")

    # å¯åŠ¨
    queue = asyncio.Queue()
    client = AsyncOpenAI(api_key=API_KEY, base_url=BASE_URL)
    sem = asyncio.Semaphore(CONCURRENCY)
    db_task = asyncio.create_task(db_writer(queue))

    # batch-style processing
    chunk_size = 500
    for i in range(0, len(tasks_to_run), chunk_size):
        chunk = tasks_to_run[i:i+chunk_size]
        print(f"æ‰¹æ¬¡ {i} - {i+chunk_size} ...")
        workers = [asyncio.create_task(worker(sem, client, queue, word)) for word in chunk]
        await asyncio.gather(*workers)

    await queue.put(None)
    await db_task
    print("âœ… æ—¥è¯­è¯å…¸æ„å»ºå®Œæˆï¼")

if __name__ == "__main__":
    asyncio.run(main())